{
	"input_dim": 26,
	"output_dim": 3,
	"hidden_sizes": [128, 256, 128, 64],
	"dropout": 0.1,
	"activation": "gelu",
	"learning_rate": 0.001,
	"weight_decay": 0.0001,
	"batch_size": 256,
	"epochs": 1000,
	"seed": 42,
	"val_split": 0.2,
	"patience": 100,
	"improvement_tol": 1e-5,
	"hpo": {
		"enabled": true,
		"n_trials": 30,
		"timeout": null,
		"study_name": "mlp_mask_search",
		"storage": null,
		"direction": "minimize",
		"seed": 42,
		"mask_presets": [
			"full",
			"no_climate",
			"power_core",
			"bess_ev_focus"
		],
		"allow_custom_mask": true,
		"dropout_range": [0.0, 0.3],
		"lr_log_range": [-4.5, -2.5],
		"weight_decay_log_range": [-6.0, -3.0],
		"batch_size_options": [128, 256, 512],
		"hidden_size_options": [
            "32x64",
            "64x128",
            "128x256",
			"256x128",
			"256x256",
			"512x256",
			"512x256x128"
		],
		"activation_options": [
			"relu",
			"gelu"
		],
		"epochs_limit": 1000,
		"final_epochs": null,
		"report_pruning": true
	}
}
